{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c717c4ed5527ef40",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Oppenheimer or Barbie?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3efdcad65c605",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41241e1358078c4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d244ecd50d82c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_bb = pd.read_csv('./data/imdb_barbie_Uncleaned.csv', header=None)\n",
    "df_op = pd.read_csv('./data/imdb_oppenhimmer_Uncleaned.csv', header=None)\n",
    "df_bb.drop_duplicates(inplace=True)\n",
    "df_op.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f218badac711910f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c35895eefc077a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "score_Reg = '(\\d{1,2})\\/\\d{1,2}\\s.*\\s'\n",
    "title_Reg = '\\d{1,2}\\/\\d{1,2}\\s(.*)'\n",
    "people_found_helpful_Reg = '([\\d,]*) out of ([\\d,]*) found this helpful'\n",
    "username_Reg = '\\d{1,2}\\/\\d{1,2}\\s.*\\s([A-Za-z0-9_-]+)\\d{2}\\s(?:January|February|March|April|June|July|August|September|October|November|December)'\n",
    "date_Reg = '(\\d{1,2}\\s(?:January|February|March|April|June|July|August|September|October|November|December)\\s\\d{4})'\n",
    "review_Reg = '\\d{1,2}\\s\\w+\\s\\d{4}\\s([\\s\\S]*)\\s[\\d,]* out of [\\d,]* found this helpful'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217712a7c60116f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean every row in data set\n",
    "\n",
    "def get_cleaned_df(dirty_df):\n",
    "    # cleaned_df = pd.DataFrame(columns=['score', 'title', 'username', 'date', 'people_found_helpful', 'review'])\n",
    "    cleaned_df = pd.DataFrame(columns=['score', 'title', 'username', 'date', 'people_found_helpful', 'total_people_viewed', 'review'])\n",
    "\n",
    "    for index in range(len(dirty_df)):\n",
    "        row = dirty_df.iloc[index][0]\n",
    "\n",
    "        score = re.findall(score_Reg, row)\n",
    "        title = re.findall(title_Reg, row)\n",
    "        username = re.findall(username_Reg, row)\n",
    "        date = re.findall(date_Reg, row)\n",
    "        people_found_helpful = re.findall(people_found_helpful_Reg, row)\n",
    "        review = re.findall(review_Reg, row)\n",
    "\n",
    "        if not score:\n",
    "            continue\n",
    "        else:\n",
    "            score = int(score[0])\n",
    "        if not title:\n",
    "            title = ['NULL']\n",
    "        if not username:\n",
    "            username = ['NULL']\n",
    "        if not date:\n",
    "            date = ['NULL']\n",
    "        if not people_found_helpful:\n",
    "            people_found_helpful = 'NULL'\n",
    "            total_people_viewed = 'NULL'\n",
    "        else:\n",
    "            total_people_viewed = int(people_found_helpful[0][1].replace(',', ''))\n",
    "            people_found_helpful = int(people_found_helpful[0][0].replace(',', ''))\n",
    "        if not review:\n",
    "            review = ['NULL']\n",
    "\n",
    "        cleaned_df.loc[index] = [score, title[0], username[0], date[0], people_found_helpful, total_people_viewed, review[0]]\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3b15b53d1961f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleand_df_bb = get_cleaned_df(df_bb)\n",
    "cleand_df_bb.drop_duplicates(subset=['username'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd002d313c0e4a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleand_df_op = get_cleaned_df(df_op)\n",
    "cleand_df_op.drop_duplicates(subset=['username'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69df9c8f568ffe0c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleand_df_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d048031108bcd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleand_df_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9456ad781d511",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleand_df_bb['isBarbie'] = 1\n",
    "cleand_df_op['isBarbie'] = 0\n",
    "\n",
    "df = pd.concat([cleand_df_bb, cleand_df_op], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae979ff4c75cc4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6f0871aefaa58",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating graphable data\n",
    "# df = df[~df['date'].str.contains('IMAX')]\n",
    "# numeric_df = pd.DataFrame(columns=['isBarbie', 'score', 'people_found_helpful', 'total_people_viewed', 'helpful_ratio', 'date', 'date_from_release','length_of_title', 'length_of_username', 'length_of_review'])\n",
    "numeric_df = pd.DataFrame(columns=['isBarbie', 'score', 'date', 'people_found_helpful', 'total_people_viewed', 'helpful_ratio','length_of_title', 'length_of_username', 'length_of_review'])\n",
    "\n",
    "numeric_df['isBarbie'] = df['isBarbie']\n",
    "numeric_df['score'] = df['score']\n",
    "numeric_df['date'] = df['date']\n",
    "numeric_df['total_people_viewed'] = df['total_people_viewed']\n",
    "numeric_df['people_found_helpful'] = df['people_found_helpful']\n",
    "numeric_df['helpful_ratio'] = df['people_found_helpful'] / df['total_people_viewed']\n",
    "numeric_df['length_of_title'] = df['title'].apply(lambda x: len(x))\n",
    "numeric_df['length_of_username'] = df['username'].apply(lambda x: len(x))\n",
    "numeric_df['length_of_review'] = df['review'].apply(lambda x: len(x))\n",
    "\n",
    "# numeric_df = numeric_df[~numeric_df['date'].str.contains('IMAX')]\n",
    "numeric_df['date'] = pd.to_datetime(df['date'], format='%d %B %Y')\n",
    "numeric_df['date_from_release'] = (numeric_df['date'] - pd.to_datetime('2023-07-23', format='%Y-%m-%d')).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1dddcfa430d215",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numeric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f06b8aed5e0fc4c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Coorelation Matrix\n",
    "\n",
    "drop_na_df = numeric_df[numeric_df['score'] != 'NULL']\n",
    "\n",
    "fig1 = plt.figure(figsize=(10, 10))\n",
    "ax1 = fig1.add_subplot(111)\n",
    "\n",
    "cmap = sns.diverging_palette(0, 255, n=256, as_cmap=True)\n",
    "\n",
    "sns.heatmap(data=drop_na_df.corr(), ax=ax1, cmap=cmap, annot=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce210dfb8c4a1982",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(10, 10))\n",
    "ax2 = fig2.add_subplot(111)\n",
    "\n",
    "sns.boxplot(data=numeric_df, x='isBarbie', y='date_from_release', ax=ax2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac20e7a102bbc4cf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_by = df.groupby('isBarbie')\n",
    "for movie_id, group_data in group_by:\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.hist(group_data['score'], edgecolor='black')\n",
    "    plt.title(f'Score Distribution for isBarbie: {movie_id}')\n",
    "    plt.xlabel('Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d0611c3e43d7f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textdata = df[['review', 'title', 'isBarbie']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda28d7c8a70bdb6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34353ff619d93f2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a493e18586159",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(textdata.drop(columns = ['isBarbie', 'title']), textdata['isBarbie'], stratify=textdata['isBarbie'], test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9a782567f69a3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")\n",
    "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730d23f71c667f43",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BERT layers\n",
    "text_input = Input(shape=(), dtype=tf.string)\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = Dense(1, activation='sigmoid')(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "bert_model = tf.keras.Model(inputs=[text_input], outputs = [l])\n",
    "\n",
    "bert_model.compile(optimizer = Adam(learning_rate = 0.2), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "bert_history = bert_model.fit(X_train, y_train, batch_size = 512, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_pred = bert_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e1a203d306a0804"
  },
  {
   "cell_type": "markdown",
   "id": "447f77de913a3452",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4588f2844bec7269",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textdata = df[['review', 'isBarbie']]\n",
    "textdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c82cb77490d2c7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = textdata[\"review\"]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X = vectorizer.fit_transform(reviews)\n",
    "\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "final_df = pd.concat([bow_df, textdata[\"isBarbie\"]], axis=1)\n",
    "# final_df = pd.concat([bow_df.reset_index(), textdata[\"isBarbie\"].reset_index()], axis=1)\n",
    "# final_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2240548f869285",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = final_df.drop(\"isBarbie\", axis=1)\n",
    "y = final_df[\"isBarbie\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947914fb9f1ada8f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(df['review']))\n",
    "# print(df['review'][2185])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bdce7020a6269c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916aa036b93de4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculates the number of instances the word \"Oppenheimer\" was used\n",
    "opp_inst = []\n",
    "from collections import Counter\n",
    "for i in range(len(df['review'])):\n",
    "    count = Counter(df['review'][i].split())\n",
    "    amount = count['Oppenheimer'] + count['oppenheimer']\n",
    "    opp_inst.append(amount)\n",
    "\n",
    "# Calculates the number of instances the word \"Barbie\" was used\n",
    "barbie_inst = []\n",
    "\n",
    "for i in range(len(df['review'])):\n",
    "    count = Counter(df['review'][i].split())\n",
    "    amount = count['Barbie'] + count['barbie']\n",
    "    barbie_inst.append(amount)\n",
    "\n",
    "# Calculates the number of instances the word \"movie\" was used\n",
    "movie_inst = []\n",
    "\n",
    "for i in range(len(df['review'])):\n",
    "    count = Counter(df['review'][i].split())\n",
    "    amount = count['Movie'] + count['movie']\n",
    "    movie_inst.append(amount)\n",
    "\n",
    "# Calculates the number of instances an exclamation mark was used\n",
    "excl_inst = []\n",
    "from collections import Counter\n",
    "for i in range(len(df['review'])):\n",
    "    count = Counter(df['review'][i])\n",
    "    amount = count['!']\n",
    "    excl_inst.append(amount)\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "new_df['opp_inst'] = opp_inst\n",
    "new_df['barbie_inst'] = barbie_inst\n",
    "new_df['movie_inst'] = movie_inst\n",
    "new_df['excl_inst'] = excl_inst\n",
    "new_df['score'] = numeric_df['score']\n",
    "new_df['date_from_release'] = numeric_df['date_from_release']\n",
    "new_df['isBarbie'] = numeric_df['isBarbie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abcf4e5d093f47",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shuffles samples\n",
    "new_df = new_df.sample(frac = 1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5290adb61f24e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = new_df.iloc[:,:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7d08721ff6ca9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "normalized_inputs = pd.DataFrame(scaler.fit_transform(x_data), columns = x_data.columns)\n",
    "normalized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf728377085ef168",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_data = new_df['isBarbie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b8f94a40bc3a1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = Sequential() # Initialising the ANN\n",
    "\n",
    "classifier.add(Dense(units = 16, activation = 'sigmoid', input_dim = 6))\n",
    "classifier.add(Dense(units = 8, activation = 'sigmoid'))\n",
    "classifier.add(Dense(units = 4, activation = 'sigmoid'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280b579784c99e26",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-03)\n",
    "classifier.compile(optimizer = opt,loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac82745d1969538d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, x_test = train_test_split(normalized_inputs, test_size=0.1, random_state=36)\n",
    "y_train, y_test = train_test_split(y_data, test_size=0.1, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171a972b033d2d6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history = classifier.fit(x_train, y_train, batch_size = 30, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9df74453322d6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd977a31eba973",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import StackingClassifier, StackingRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b373afb5f66ae9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
